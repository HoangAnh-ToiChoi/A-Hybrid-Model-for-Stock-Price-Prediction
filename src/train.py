import numpy as np
import os
import pandas as pd
from model import build_cnn_lstm_model
from config import TIME_STEP, EPOCH, BATCH_SIZE, LR, DATA_PATH
from preprocess import load_data # hÃ m táº£i dá»¯ liá»‡u tá»« file csv
import glob 
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau


def train_model(csv_file):
    # Láº¥y dá»¯ liá»‡u tá»« file csv
    stock_symbol = os.path.basename(csv_file).replace('.csv', '')
    
    print(f"\n{'='*40}")
    print(f"Äang táº£i dá»¯ liá»‡u tá»« mÃ£ cá»• phiáº¿u: {stock_symbol}\n")
    print(f"\n{'='*40}")

    try:
        x_train, y_train, x_test, y_test, scaler = load_data(csv_file, TIME_STEP)
        print(f"Dá»¯ liá»‡u Ä‘Ã£ {stock_symbol} Ä‘Æ°á»£c táº£i lÃªn vÃ  Ä‘Ã£ sáºµn sÃ ng ğŸ’ª \n")
        print(f"Shape train: {x_train.shape}\n")
        print(f"Shape test: {x_test.shape}\n")
    except Exception as e:
        print(f"Lá»—i khi táº£i dá»¯ liá»‡u. Lá»—i Ä‘á»c file {csv_file}", e)
        return
    print("\n Báº®T Äáº¦U KHá»I Táº O MODEL HYBRID CNN-LSTM \n")
    model = build_cnn_lstm_model(time_step = TIME_STEP, features = 1, learning_rate = LR)
    model.summary()

    print (f"\n QUÃ TRÃŒNH TRAIN Dá»® LIá»†U {stock_symbol} Báº®T Dáº¦U: ")

    checkpoint = [
            # LÆ°u model tá»‘t nháº¥t
    ModelCheckpoint(f"experiments/{stock_symbol}.keras", monitor='val_loss', save_best_only=True, verbose=1),
    
    # Ká»¸ THUáº¬T Má»šI: Giáº£m Learning Rate khi loss Ä‘i ngang
    # Náº¿u val_loss khÃ´ng giáº£m sau 3 epoch -> chia Ä‘Ã´i tá»‘c Ä‘á»™ há»c
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1),
    
    # Dá»«ng sá»›m náº¿u khÃ´ng khÃ¡ hÆ¡n sau 10 epoch
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)
    ]

    history = model.fit(
        x_train, y_train, # láº¥y dá»¯ liá»‡u vÃ  káº¿t quáº£ ra há»c 
        validation_data = (x_test, y_test), # dÃ¹ng dá»¯ liá»‡u test vÃ  káº¿t quáº£ test Ä‘á»ƒ kiá»ƒm tra sau khi Ä‘Ã£ há»c háº¿t 1000 cÃ¢u há»i
        epochs = EPOCH, # láº·p láº¡i 32 láº§n
        batch_size = BATCH_SIZE, # 1000 cÃ¢u há»i thÃ¬ má»—i láº§n há»c chá»‰ 32 cÃ¢u Ä‘áº¿n khi háº¿t 1000 cÃ¢u thÃ¬ quay láº¡i dÃ²ng validation_data
        callbacks = checkpoint
    )

    save_dir = 'experiments'
    if not os.path.isdir(save_dir):
        os.makedirs(save_dir)
    save_path = os.path.join(save_dir, f"{stock_symbol}.keras")
    model.save(save_path)
    print(f"Ä‘Ã£ lÆ°u model táº¡i: {save_path}")


def main():
    csv_files = glob.glob(os.path.join(DATA_PATH, '*.csv'))

    if not csv_files:
        print(f"KhÃ´ng tÃ¬m tháº¥y file CSV trong thÆ° má»¥c {DATA_PATH}")
        return
    
    print(f"ğŸ” TÃ¬m tháº¥y {len(csv_files)} file dá»¯ liá»‡u: {[os.path.basename(f) for f in csv_files]}")

    for csv_file in csv_files:
        train_model(csv_file)
    print("\nğŸ‰ ÄÃ£ hoÃ n thÃ nh training cho táº¥t cáº£ cÃ¡c mÃ£ cá»• phiáº¿u!")
    print("hehehe ğŸš€")

if __name__ == '__main__':
    main()